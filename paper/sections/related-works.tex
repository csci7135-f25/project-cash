\paragraph{Modular Abstract Interpreters}
The isolation of complex components in programming language definitions has been explored extensively in prior work. \citet{Horn10} introduced a technique for abstracting the program store, thereby transforming an infinite execution tree into a finite state graph. This foundational work was extended by \citet{Sergey18}, who employed a monadic store to decouple store execution from program execution. This modularization simplified the interpretation process and enabled independent reasoning about specific components. Through the use of monadic state, they achieved orthogonalization of semantics and facilitated reusability across distinct interpreters. Our work adopts a similar approach by factoring state into a set of lowering handlers, which permits developers to define state representations flexibly and reuse them across multiple instantiations. This design does not constrain implementations to exclusively monadic state representations, permitting any style of state encapsulation desired. We extend this technique further by modularizing the program's interaction with state, such that both state representations and state access patterns (retrievals and updates) can be handled in any way. In their Sturdy framework, Keidel et al.~\cite{Keidel18, Keidel19} employed arrow transformers to achieve gradual, automatic soundness proofs. While their approach provides soundness guarantees compositionally, it is limited to non-relational domains and necessitates a generic interpreter implementation for each target language, offering flexibility primarily along the abstract domain axis. We pursue an additional dimension of modularity beyond Sturdy by reducing the overhead required to extend syntax and by incorporating modularity for control flow as a fundamental design principle. More recently, \citet{Michelland24} advanced monadic modularity through their I-Tree-based framework, composing state and control flow monads to establish a sound metatheory formalized in Roq (Coq). Their approach supports modular analyses such as binding-time analysis, and we pursue similar modularity objectives while aiming to reduce implementation complexity and eliminate the need for intricate transformer stacks.

% Monat \cite{Monat21} developed the MOPSA abstract interpreter with a slightly different approach. MOPSA analysis relies on a project configuration file, specified by the programmer running the analysis, to instruct which domains are being used and how they are being composed. In this configuration domains are represented as DAGs or Directed Acyclic Graphs, causing evaluated expressions to cascade through each domain until a domain can perform a meaningful analysis. In other words the programmer must specify a the order of domains to be used in analysis, each used until one domain can return a value for each expression being analyzed. There was great care given to the composition of domains. It is mainly accomplished by taking the reduced product of two domains. Communication between domains is handled in part by interfaces that allow domains to communicate via queries and a generic merge function that makes states operable by multiple domains. To get around the issue of monolithic generic interpreters, MOPSA opts for a shared AST. By shared it means that each language MOPSA can analyze must be represented by their AST. This simplifies analysis but means that certain languages could be incompatible with the AST and could lead to extensions needing to made in the future. Additionally there is a computational cost to supporting a wide variety of AST nodes for each language feature of every language supported.

\paragraph{Effect-Based Interpreters}
The application of algebraic and lexically scoped effects to interpreter construction represents a relatively recent development. \citet{Reinders23} explored this theoretical direction in preliminary work, and \citet{Bunkenburg24} developed that theory into practice, implementing a modular interpreter using effect handlers embedded in Haskell, representing one of the earliest implementations of this approach. While their work focused on concrete interpretation of the Curry language, Curry's inherent support for non-determinism parallels the non-determinism encountered in abstract interpretation. This demonstrated the utility of effect handlers for control flow manipulation, which our work adopts and generalizes to more comprehensive abstract domains and applications beyond the Curry language. Prior to the exploration of a priori effect systems Kisylov explored simulating effects with Free Monads ~\cite{Kiselyov15}. In his work effects are represented as free monads with effectful operations denoting their effects as a coproduct of free monads in the type signature. Many effect systems leverage similar constructs in their implementations. However, for top level use it presents the overhead of manually injecting and lifting free monads. Our Lean implementation of cumulative semantics achieved similar modularity and functionality by directly passing continuations and leveraging typeclasses, removing the need for monadic encapsulation and the plumbing that it entails.

\paragraph{Type Class-Based Interpretation} Type classes have long been used to modularize semantics, as introduced in Haskell by \citet{Swierstra08}. Our work builds on the idea of tagless final interpreters, where the initial encoding is an unsubstantiated interpreter and the final encoding is a substantiated one. In place of the Haskell modules used by \citet{Carette09}, we use Lean's type classes. While their approach focuses on modularizing the syntax and semantic domain, our cumulative semantics further decouples the control-flow strategy (via elimination handlers) from the domain operations.

% More sources to consider adding:
% jinExtensibleMetatheoryMechanization2023
% binkley_orbs_2014
% yang_language-agnostic_2022
% houdaillePolyglotASTEnabling2023
% mineDesignModularPlatform2018 - mopsa
% Data types Ã  la carte (Wouter Swierstra, JFP 2008)
% brandlModularAbstractDefinitional2023 - similar to sturdy
% reynoldsDefinitionalInterpretersHigherorder1972 - similar to how we decouple control flow

% ---------------------- notes on individual sources--------------------------------
% \paragraph{Van Horn Abstracting abstract machines}\cite{Horn10}: Sergey built on this idea, it seems to allow for the isolation of more complex ideas, allowing for their simplification and independent reasoning. They accomplish this by abstracting the store (and making it finite), turning an infinite execution tree into a finite state graph. 
% \paragraph{Sergey Monadic Abstract Interpreters}\cite{Sergey18}: 
% This work seems to mostly be based off of a previous work (abstracting abstract machines) but also using a monad to capture state. Their essential claim seems to be similar to ours in that they are making the semantics orthogonal(and reusable) across different interpreters with the monadic approach. By using a monadic state you delay any choices in your interpreter until you actually assemble it. In my monadic attempt we take the idea of using a monadic state to track it easily through everything, keeping its representation orthogonal to what we want. The monadic implementation of intro and elim is similar to this paper, but slightly different because we retain a more precise control over control flow. Also, our version is done in a more modern and dependently typed language leaving room to reason and prove things if we wanted to.
% \paragraph{Michelland Monadic Modular Verification}\cite{Michelland24}:
% They advanced the usage of monadic modularity with their ITree-based framework for abstract interpretation, composing state and control flow monads for sound meta-theory in Roq. Their approach supports modular analyses (e.g., binding-time analysis) but requires complex transformer stacks. Their work is also done in a dependently type language like ours.
% % \paragraph{Keidel Sturdy}\cite{Keidel18, Keidel19}:
% The goal of this work is automatic soundness proofs for components, so not centrally aligned with what we are going for. Their approach provides soundness guarantees for free but is fixed to non-relational domains and requires an implementation of a monolithic, generic interpreter for every language. It accomplishes modularity with arrow transformers which are generally more rigid than effects or monads with control flow manipulation.
% \paragraph{Reinder Modular Effect Interpreter}\cite{Reinders23}:
% This short paper introduced the idea to make an effect based interpreter in theory, and played with a small toy example of it.
% \paragraph{Bunkenburg Making a Curry Interpreter} \cite{Bunkenburg24}:
% They started using effect handlers embedded in Haskell to build a modular interpreter, one of the first of its kind. Its focus was on concrete interpretation of the Curry language, but Curry already supports non-determinism which is the same as non determinism in abstract interpretation. This demonstrated the usefulness of effects for control flow manipulation, which we use and extend to more generic domains in our work.

